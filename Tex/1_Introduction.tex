\section{Introduction} \label{tex:introduction}

Machine Learning (ML) has been a very useful tool in many areas for a long time. One of the biggest leaps in the discovery of the computer was Alan Turing's learning machine that was used to decrypt the German cipher during World War II \cite{turing}. Alan Turing was widely considered the father of computer science and artificial intelligence\cite{Beavers2013}. Ever since his work and with computers becoming better and more accessible, people have studied different ways of making machines learn different tasks. Today ML is used for everything from recognising handwriting to diagnosing breast cancer\cite{Khuriwal2018}. 

One of the most famous and versatile ML algorithms is the neural network (NN), which builds upon the idea of the brain with neurons firing up and sending information to each other through a network. NNs are very powerful since they are easy to train (finding the optimal weights), and easy to modify to fit almost any given problem. This means that NNs achieve state-of-the-art performance in a large variety of problems. Artificial neural networks (ANNs) are simply a set of neurons arranged in layers sending information from one layer to another from the input to the output. Stacking multiple layers of neurons makes the algorithm able to extract higher level features\cite{deepLearning}, hence many layers (deep learning) are often preferred for complex problems.

A big area in ML and NN research is image classification and detection, which is respectively to classify an image into a set of predetermined classes or detect a given object in an image. By far the major method in learning images is the convolutional neural network (CNN). In a CNN a number of filters are trained and run through the image to calculate activations. These filters will then be trained to see different features in the image such as lines or curves. Stacking multiple layers of convolutions enables the algorithm to learn more abstract features such as faces, printed text or wrinkly clothes\cite{Yosinski2015}. CNNs are the preferred NN architectures for image analysis, since they keep achieving state-of-the-art performance.

\subsection{The problem}
Even though NNs are very powerful and there is nothing to be said about their ability to learn, there is one problem. The amount of parameters to be trained and the amount of time it takes grow rapidly as the number of layers and the amount of neurons in these layers grow. Also the amount of parameters grow exponentially as the input resolution increases. For instance the MNIST data set, which consists of $28\times28$ pixel values per image will need $28\cdot28 = 784$ input neurons. If one is to have a fully connected (dense) layer from these inputs to another layer of just 100 neurons, the amount of parameters to be trained is $784 * 100 + 100 = 784,100$ (there is one bias term per neuron). Denil et al. found in 2013 that many of the weights in a deep NN are redundant\cite{Denil2013}. They found that if only a fraction of the weights were trained and the rest predicted from these, they would get close to the same accuracy as a fully trained network. This means that a high accuracy should be obtainable from a network with fewer parameters, if the architecture and algorithm itself are chosen wisely.

Many approaches have been attempted to solve this problem. For instance Liu et al. in 2015 used pruning to zero-out\footnote{Setting insigificant parameters to 0 (parameters that are already relatively close to 0)} more than 90 \% of the learned parameters with a loss in accuracy of under 1\% on a given data set. Also there have been many attempts to use tensor decomposition to reduce the number of parameters. Tensor decomposition is a way of approximating a multi-dimensional data array using a limited amount of parameters by looking at the variation in different dimensions. Numerous approaches have been generalizing this concept to change the architecture as in the work of Lebedev et al. in \cite{Lebedev2015} and of Wang et al. in 2016 \cite{Wang2016}. These methods decompose the weights of a pre-trained network and use the decompositions in the new architecture. After fine-tuning the performance should be increased both with respect to the number of parameters and the computation time, while the accuracy should remain approximately the same.

\subsection{Aim of this project}
This thesis investigates previous attempts and other potential approaches to evaluate the potential synergistic effects of using these methods within a deep NN. The aim is to examine the effects of using different tensor decomposition methods either before (as input) or within a potentially deep NN. The methods will be investigated and compared to baseline results in order to analyze the accuracy, running times, and number of parameters. Two data sets will be used to assess the performance differences. The first is the rather simple MNIST (Modified National Institute of Standards and Technology) data set\cite{MNIST}, which consists of handwritten digits from 0 to 9. The other is the THETIS (Three dimEnsional TennIs Shots) data set \cite{Gourgari2013}, which consists of videos of individuals performing different types of tennis shots. The purpose is to first apply the methods to the simpler MNIST data set, since this is well-studied and relatively easy to work with, and then apply them to the more complicated THETIS data set in order to test the methods on a more demanding problem.