\section{Abstract}

This thesis covers the development and assessment of two different methods of applying Tucker decomposition to neural networks. The motivation of the project is to evaluate the potential synergistic effects of using tensor decomposition to speed-up the computational neural network evaluation. In assessing the performance of the two methods, two data sets are used; the MNIST data set of handwritten digits and the THETIS data set which consists of videos of individuals performing tennis shots.

\noindent Method 1 compresses the input into a very simple artificial neural network (ANN) trying to aid the network by carrying out some of the learning beforehand. Method 2 compresses an already trained convolutional neural network (CNN) by manipulating the architecture in order to fit the Tucker-decomposed weight kernels. This method builds on a previously proposed method for images, that is generalized to videos in this thesis.

\noindent For Method 1 the theoretical speed in terms of the number of FLOPs and the time observed is exceeded before reaching the same accuracy as when simply using the full input into the ANN, limiting the potential of this method. For Method 2 the calculated theoretical speed-up makes this method promising, but this speed-up is not met by the observed timing results. Method 2 results in an observed speed-up of 1.34 times (6.1 times theoretical) for the architecture developed for the THETIS data set and a speed-up of 1.82 times for the well-known VGG-16 architecture (5.6 times theoretical), while the architecture for the MNIST data set is not sped-up, though a 3.45 times speed-up is theoretically expected.

\noindent It is concluded that Method 1 only works for very simple problems, while Method 2 has more potential and can be used for bigger CNN architectures for both images and videos. The lack of observed speed-up, compared to the theoretical for Method 2, is believed to stem from the inefficiency of the $1\times 1\times 1$ convolution and due to the penalty suffered by the computer for not being able to parallelize the computations properly, but these claims require further investigation.