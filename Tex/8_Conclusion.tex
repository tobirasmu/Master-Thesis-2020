\section{Conclusion} \label{tex:conclusion}
The aim of this thesis was to evaluate the synergistic effects of using tensor decomposition methods within a NN. Two methods have been proposed to do this. Method 1 use Tucker decomposition to compress the input into a NN in order to decrease the number of inputs into a very simple ANN. Method 2 takes a pre-trained network and changes the architecture to fit the compressed version of the weight kernels. Both methods have been tested on both data sets in order to assess the performance changes. Baseline architectures have been chosen and baseline results have been established. All timing have been done both on a CPU and a GPU in order to examine potential speed-up differences using each type of processing unit. This difference however was shown to be insignificant.

The results from Method 1 shows that it works well for very simple problems, where the observations in the same class are very similar and between classes look different. When the complexity rises it falls short. In order to get the same accuracy as simply using the whole input into the ANN for the THETIS data set, the rank would need to be increased to a point where both the theoretical speed in terms of the number of FLOPs and the measured computation time would be exceeded. For the MNIST data set the accuracy for the compressed model would never meet that of the full input network using up to 7.6 times the number of FLOPs and almost 4 times the time running on a CPU. Due to these results Method 1 was deemed to have limited potential.

Method 2 did result in a speed-up for the THETIS data set and for the VGG-16 data set, however far from what was expected from the theoretical speed-ups calculated from the number of FLOPs. For the compressed THETIS architecture the observed speed-up was 1.34 times for CPU and 1.93 times for GPU (exp. 6.12 times) and for the VGG-16 it was 1.82 times for both (exp. 5.55 times). For the MNIST data set the compressed version took almost twice the time of the original network. This shortcoming of observed speed-up is believed to stem from the cache-inefficiency of the $1\times 1 (\times 1)$ convolution also observed by Kim et al. in \cite{Kim2016}, and from the time penalty suffered by the computer for not being able to parallelize the computations properly. The accuracy drop was minimal in all cases after having fine-tuned the compressed models using only a fraction of the weights ($\frac{1}{33}$ for THETIS, $\frac{1}{4.6}$ for MNIST, and $\frac{1}{6.1}$ for VGG-16). Method 2 is believed to be appropriate for bigger CNN architectures for both images and videos due to its ability to speed-up and decrease the number of parameter while maintaining the same accuracy. However more work needs to be done in order to check if the speed-up is more pronounced for devices with less computing power, and to investigate the causes of the inefficiency of the $1\times 1(\times 1)$ convolution.