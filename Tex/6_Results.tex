\section{Results}
Like in the methods section, this section will also be in two parts. This is due to the two compression methods, that are to be tested, are so different in nature and cannot be directly compared. To compare the methods, the a set of metrics will be applied to the original and compressed models. The metrics are:
\begin{itemize}
    \item \textbf{Accuracy} - especially the accuracy drop is an important metric in comparing the compressed model to the full model
    \item \textbf{Number of Parameters} - how much space the model takes to store
    \item \textbf{Theoretical speed} - based on the number of FLOPs, calculated using the formulas given in \autoref{tex:computational_complexity}.
    \item \textbf{Actual speed} - how long it takes to compute a forward push. Computed many times reporting the mean and standard deviation of the time it takes. Due to potential differences in performance improvements, the methods will both be timed running on a CPU and GPU.
\end{itemize}
Initially the results of the method of decomposing the input will be given, followed by the results of decomposing a pre-trained network.

\subsection{Decomposing the Input}
In order to get a better understanding of what happens using this method, an experiment with only two classes for each data set and a rank of 2 will be carried out. Afterwards the results will be listed using different ranks for the input in order to assess performance differences.

\subsubsection{Experiment with low rank}
In the following an experiment is carried out to check whether the decomposition itself can carry much of the training. Since we have only 2 classes for the THETIS data set, and for the sake of the experiment 2 digits from the MNIST data set will be used. Since there are 2 classes in each data set, an initial rank of 2 will be experimentally chosen in the between sample dimension. The results for both the data set are described in the following.

\paragraph{Using MNIST 3s and 4s}
Only the MNIST observations depicting either a 3 or a 4 will be considered in this experiment. These digits are chosen due to their distinct shapes, hence ease of classification. Since the purpose is to make the algorithm find the differences between the two different digits, the spatial dimensions will not be decomposed. Using the experimental rank of 2, the decomposition of $N$ stacked 3s and 4s becomes:
\begin{equation}
    \tensor{X}^{N\times 28\times 28} \approx \tensor{G}^{2 \times 28 \times 28} \times_1 \bs{A}^{N\times 2} \qquad \Leftrightarrow \qquad \bs{X}_{(1)} \approx \bs{A}^{N\times 2} \ \bs{G}^{2 \times 28\cdot 28}_{(1)}
\end{equation}
Where $\bs{A}$ is the loading matrix in the dimension corresponding to different pictures. With the rank equal to 2, $\bs{A}$ holds 2 values per picture that should ideally be separating the two digits that is to be trained. \autoref{fig:decompExample3_4} shows how the decomposition of the first 100 training examples turns out. It seems the decomposition is able how to find the "general 3" and the "general 4", and then simply use the loadings of $\bs{A}$ to specify how much of each should be used to represent every observation. \autoref{fig:loadingAMatrix} shows a scatter-plot of the values of $\bs{A}$ colored to show the loadings corresponding to 3s and 4s respectively. There is some overlap between the two clusters, but it seems that they can be fairly distinguished. Using the mean of $\bs{A}$ of the the 3s, 4s and overall respectively as loadings in the decomposition yields the approximated pictures shown in \autoref{fig:loadingsOfA}b-d.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Pics/06_results/3_4_original.png}
        \captionsetup{width=.9\linewidth}
        \caption{Original MNIST training examples including only 3s and 4s.}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Pics/06_results/3_4_decomp.png}
        \captionsetup{width=.9\linewidth}
        \caption{Approximated versions of the training examples on the left, using the decomposition.}
    \end{subfigure}
    \captionsetup{width=.95\linewidth}
    \caption{MNIST training examples before and after decomposing with only rank 2 in the input dimension. Notice how the decomposed 3s and 4s look more standardized. It seems that every picture is a part standardized 3 and a part standardized 4. Notice how digits that look relatively odd results in less certain approximation.}
    \label{fig:decompExample3_4}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{0.99\linewidth}
        \includegraphics[width=\linewidth]{Pics/06_results/LoadingsOfAScatterMNIST.png}
        \caption{Scatter plot of the 2 loadings of the loading matrix $\bs{A}$ for the MNIST 3s and 4s respectively using rank 2 in the input dimension. The mean of the 2 clusters and overall is also marked with black.}
        \label{fig:loadingAMatrix}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
    \centering
        \includegraphics[width=.5\linewidth]{Pics/06_results/general4.png}
        \caption{The mean of 4s loadings}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
    \centering
        \includegraphics[width=.5\linewidth]{Pics/06_results/general3.png}
        \caption{The mean of 3s loadings}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
    \centering
        \includegraphics[width=.5\linewidth]{Pics/06_results/general.png}
        \caption{The mean of all loadings}
        \label{Hej}
    \end{subfigure}
    \caption{Scatter plot of the 2 loadings of $\bs{A}$ for the MNIST 3s and 4s using rank 2 including mean in each of the clusters and overall. Using these means as loadings in the approximation gives the approximated "general" 3, 4 and overall given in \textbf{(b)-(d)}. Notice how the overall mean gives a mixture of a 3 and a 4.}
    \label{fig:loadingsOfA}
\end{figure}

This all comes down to the loadings of $\bs{A}$ holding a great deal of information about which pictures are 3s and which are 4s. This information could be used as input into the NN instead of the actual pictures potentially reducing the number of parameters dramatically (from 784 to 2 input neurons in this example). 

\paragraph{Using THETIS forehand flat and backhand}
Following the same procedure as for the MNIST 3s and 4s we set the rank of the decomposition to 2. Stacking $N$ videos and decomposing with rank 2 in the between sample dimension yields:
\begin{equation}
    \tensor{X}^{N\times 4 \times 28 \times 120 \times 160} \approx \tensor{G}^{2 \times 4 \times 28 \times 120 \times 160} \times_1 \bs{A}^{N\times 2}
\end{equation}
Now the loading matrix $\bs{A}$ holds 2 values for each observation that should ideally be separating the two types of shots. Making the scatter plot of the loadings from $\bs{A}$ colored with the type this is however not the case. The plot is shown in \autoref{fig:scatter_plot_THETIS}, where it is clear that there are two clusters, but the clusters do not separate the type of shot, but the location of the video. The mean of each of the clusters have been used to approximate the videos given in \autoref{fig:scatter_plot_THETIS}(b) and (c)
\begin{figure}
    \centering
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=0.65\linewidth]{Pics/06_results/scatter_loadings_THETIS.png}
        \captionsetup{width=.95\linewidth}
        \caption{Scatter plot of the loadings of $\bs{A}$ for the THETIS forehands and backhands. There seems to be two clusters, but they are not divided according to the shot type, but rather the background information. The mean of the two clusters are given, which are used to approximate the videos in \textbf{(b)} and \textbf{(c)}.}
    \end{subfigure}
    \begin{subfigure}{.45\linewidth}
        \centering
        \captionsetup{width=.95\linewidth}
        \includegraphics[width=\linewidth]{Pics/06_results/loc1.png}
        \caption{Approximation using the loadings of the mean of the little cluster in \textbf{(a)}. This corresponds to one of the two locations.}
    \end{subfigure}
    \begin{subfigure}{.45\linewidth}
        \centering
        \captionsetup{width=.95\linewidth}
        \includegraphics[width=\linewidth]{Pics/06_results/loc2.png}
        \caption{Approximation using the loadings of the mean of the big cluster in \textbf{(a)}. This corresponds to one of the two locations.}
    \end{subfigure}
    \begin{subfigure}{.45\linewidth}
        \centering
        \captionsetup{width=.95\linewidth}
        \includegraphics[width=.78\linewidth]{Pics/06_results/loc_1_real.png}
        \caption{An example of the location seen approximated in \textbf{(b)}}
    \end{subfigure}
    \begin{subfigure}{.45\linewidth}
        \centering
        \captionsetup{width=.95\linewidth}
        \includegraphics[width=.78\linewidth]{Pics/06_results/loc_2_real.png}
        \caption{An example of the location seen approximated in \textbf{(c)}}
    \end{subfigure}
    \caption{The loadings of $\bs{A}$ for the THETIS data illustrated by a scatter plot in \textbf{(a)}, and used to make the two approximation \textbf{(b)} and \textbf{(c)} by estimating the mean of each cluster seen in the scatter plot.}
    \label{fig:scatter_plot_THETIS}
\end{figure}

\subsubsection{Results for MNIST}
The results for MNIST using the method that decomposes the input are given in \autoref{tab:res_input_MNIST}. Here the different models have been trained and timed, reporting the mean and the standard deviation of the time of 100,000 forward pushes through the network. Since the data is small and the models are all very fast, every forward push is conducted using 10,000 observations, which means that a total of $10^{9}$ forward pushes have been timed. In \autoref{} the brackets holds the time of each of the two parts of the algorithm, i.e. estimating the input loadings, and pushing through the ANN. 

It seems... 

\begin{table}[H]
\small
\caption{The results of running the input decomposition method on the MNIST data set using different ranks for the decomposition. The time is reported as the mean and standard deviation of 1000 samples where 10 observations are evaluated using the model. }
\label{tab:res_input_MNIST}
\begin{tabular}{c|cccc|c}
\textbf{Rank}     & \textbf{\begin{tabular}[c]{@{}c@{}}Parameters\\ (K)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}FLOPs\\ (K)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Time CPU\\ (ms)\end{tabular}}                  & \textbf{\begin{tabular}[c]{@{}c@{}}Time GPU\\ (ms)\end{tabular}}                  & \textbf{\begin{tabular}[c]{@{}c@{}}Accuracy\\ (\%)\end{tabular}} \\ \hline
\textbf{2}        & 1.83                                                              & 3.58                                                         & \begin{tabular}[c]{@{}c@{}}$1.481 \pm 0.025$ \\ $(= 0.904 + 0.647 )$\end{tabular} & $0.149 \pm 0.012$ $(= 0.014 + 0.118 )$                                            & \textbf{33.61}                                                  \\
ratio             & 0.11                                                              & 0.11                                                         & 0.871                                                                             & 1.155                                                                             & 0.36                                                            \\ \hline
\textbf{5}        & 4.25                                                              & 8.41                                                         & \begin{tabular}[c]{@{}c@{}}$2.445 \pm 0.039$\\  $(= 1.885 + 0.551 )$\end{tabular} & $0.144 \pm 0.011$ $(= 0.013 + 0.115 )$                                            & \textbf{52.20}                                                  \\
ratio             & 0.25                                                              & 0.26                                                         & 1.438                                                                             & 1.116                                                                             & 0.55                                                            \\ \hline
\textbf{7}        & 5.86                                                              & 11.62                                                        & \begin{tabular}[c]{@{}c@{}}$3.114 \pm 0.047$ \\ $(= 2.525 + 0.565 )$\end{tabular} & $0.142 \pm 0.010$ $(= 0.013 + 0.113 )$                                            & \textbf{61.71}                                                  \\
ratio             & 0.35                                                              & 0.37                                                         & 1.832                                                                             & 1.101                                                                             & 0.65                                                            \\ \hline
\textbf{10}       & 8.27                                                              & 16.44                                                        & \begin{tabular}[c]{@{}c@{}}$1.660 \pm 0.033$\\  $(= 0.968 + 0.681 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.141 \pm 0.011$\\  $(= 0.013 + 0.113 )$\end{tabular} & \textbf{67.55}                                                  \\
ratio             & 0.50                                                              & 0.52                                                         & 0.976                                                                             & 1.093                                                                             & 0.72                                                            \\ \hline
\textbf{15}       & 12.30                                                             & 24.48                                                        & \begin{tabular}[c]{@{}c@{}}$1.906 \pm 0.035$ \\ $(= 1.372 + 0.527 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.141 \pm 0.011$\\  $(= 0.013 + 0.113 )$\end{tabular} & \textbf{72.14}                                                  \\
ratio             & 0.74                                                              & 0.77                                                         & 1.121                                                                             & 1.093                                                                             & 0.76                                                            \\ \hline
\textbf{20}       & 16.32                                                             & 32.51                                                        & \begin{tabular}[c]{@{}c@{}}$1.965 \pm 0.031$\\  $(= 1.354 + 0.598 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.142 \pm 0.011$\\  $(= 0.014 + 0.113 )$\end{tabular} & \textbf{79.41}                                                  \\
ratio             & 0.98                                                              & 1.02                                                         & 1.156                                                                             & 1.101                                                                             & 0.84                                                            \\ \hline
\textbf{25}       & 20.35                                                             & 40.55                                                        & \begin{tabular}[c]{@{}c@{}}$1.943 \pm 0.031$ \\ $(= 1.407 + 0.527 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.141 \pm 0.011$\\  $(= 0.014 + 0.113 )$\end{tabular} & \textbf{74.19}                                                  \\
ratio             & 1.22                                                              & 1.28                                                         & 1.143                                                                             & 1.093                                                                             & 0.79                                                            \\ \hline
\textbf{30}       & 24.37                                                             & 48.58                                                        & \begin{tabular}[c]{@{}c@{}}$2.397 \pm 0.035$ \\ $(= 1.785 + 0.599 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.142 \pm 0.011$\\  $(= 0.015 + 0.115 )$\end{tabular} & \textbf{74.66}                                                  \\
ratio             & 1.46                                                              & 1.53                                                         & 1.410                                                                             & 1.101                                                                             & 0.79                                                            \\ \hline
\textbf{40}       & 32.42                                                             & 64.65                                                        & \begin{tabular}[c]{@{}c@{}}$2.298 \pm 0.039$ \\ $(= 1.756 + 0.528 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.144 \pm 0.011$ \\ $(= 0.024 + 0.116 )$\end{tabular} & \textbf{74.89}                                                  \\
ratio             & 1.94                                                              & 2.04                                                         & 1.352                                                                             & 1.116                                                                             & 0.79                                                            \\ \hline
\textbf{50}       & 40.47                                                             & 80.72                                                        & \begin{tabular}[c]{@{}c@{}}$3.005 \pm 0.043$\\  $(= 2.242 + 0.752 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.146 \pm 0.013$\\  $(= 0.025 + 0.114 )$\end{tabular} & \textbf{81.56}                                                  \\
ratio             & 2.43                                                              & 2.54                                                         & 1.768                                                                             & 1.132                                                                             & 0.86                                                            \\ \hline
\textbf{70}       & 56.57                                                             & 112.86                                                       & \begin{tabular}[c]{@{}c@{}}$3.661 \pm 0.047$\\  $(= 3.042 + 0.581 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.144 \pm 0.010$ \\ $(= 0.022 + 0.115 )$\end{tabular} & \textbf{75.13}                                                  \\
ratio             & 3.39                                                              & 3.56                                                         & 2.154                                                                             & 1.116                                                                             & 0.80                                                            \\ \hline
\textbf{100}      & 80.72                                                             & 161.07                                                       & \begin{tabular}[c]{@{}c@{}}$4.796 \pm 0.067$ \\ $(= 3.897 + 0.823 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.144 \pm 0.011$ \\ $(= 0.027 + 0.114 )$\end{tabular} & \textbf{83.98}                                                  \\
ratio             & 4.84                                                              & 5.08                                                         & 2.821                                                                             & 1.116                                                                             & 0.89                                                            \\ \hline
\textbf{150}      & 120.97                                                            & 241.42                                                       & \begin{tabular}[c]{@{}c@{}}$6.664 \pm 0.086$\\  $(= 5.655 + 0.849 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$0.145 \pm 0.012$\\  $(= 0.034 + 0.115 )$\end{tabular} & \textbf{83.65}                                                  \\
ratio             & 7.25                                                              & 7.61                                                         & 3.920                                                                             & 1.124                                                                             & 0.89                                                            \\ \hline
\textbf{Original} & 16.68                                                             & 31.73                                                        & $1.700 \pm 0.052 $                                                                & $0.129 \pm   0.013$                                                               & \textbf{94.44}                                                 
\end{tabular}
\end{table}

\subsubsection{Results for THETIS}
The results for THETIS are given in \autoref{tab:res_input_THETIS}. The time is given as the mean and standard deviation of the time based on 1000 forward pushes through the different models, assuming the core have already been matricized and inverted in \eqref{eq:estimation_of_loading_A}. The brackets holds the time broken down into the two parts - estimating the loading matrix and pushing through the ANN.

Interestingly the accuracy of the decomposed models only match that of the original network, when the computational complexity and the computation time are exceeded. This fact casts doubt on the functionality of this method. When running on the GPU the computation time is exceeded at an even lower rank than the CPU, which could mean that the GPU is more penalized by the split, i.e. the algorithm. One thing that is also interesting is that the estimation of the loading matrix accounts for the majority of the computation time by far. This is due to the estimation of the loading matrix getting the full input which means a lot of parameters.

\begin{table}
\centering
\caption{Results for running the input decomposition algorithm using different ranks for the decomposition. The time is given as the mean and standard deviation of 1000 forward pushed for each model. The numbers in brackets correspond to the break-down of the time of the estimation of the input loadings and the forward push through the network respectively. Notice how the accuracy of the original network is not reached before exceeding the computational complexity and time.}
\label{tab:res_input_THETIS}
\small
\begin{tabular}{c|cccc|c}
\textbf{Rank}     & \textbf{\begin{tabular}[c]{@{}c@{}}Parameters\\ (M)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}FLOPs \\ (M)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Time CPU \\ (ms)\end{tabular}}                     & \textbf{\begin{tabular}[c]{@{}c@{}}Time GPU \\ (ms)\end{tabular}}                 & \textbf{\begin{tabular}[c]{@{}c@{}}Accuracy \\ (\%)\end{tabular}} \\ \hline
\textbf{30}       & 64.52                                                             & 129.03                                                        & \begin{tabular}[c]{@{}c@{}}$30.534 \pm 0.325$ \\ $(= 30.322 + 0.081 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.340 \pm 0.073$ \\ $(= 0.246 + 0.209 )$\end{tabular} & \textbf{70}                                                      \\
ratio             & 0.30                                                              & 0.30                                                          & 0.33                                                                                  & 0.33                                                                              & 0.76                                                             \\ \hline
\textbf{40}       & 86.02                                                             & 172.04                                                        & \begin{tabular}[c]{@{}c@{}}$38.481 \pm 0.371$\\  $(= 38.085 + 0.087 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.496 \pm 0.102$\\  $(= 0.357 + 0.243 )$\end{tabular} & \textbf{70}                                                      \\
ratio             & 0.40                                                              & 0.40                                                          & 0.42                                                                                  & 0.47                                                                              & 0.76                                                             \\ \hline
\textbf{50}       & 107.53                                                            & 215.05                                                        & \begin{tabular}[c]{@{}c@{}}$47.790 \pm 0.300$ \\ $(= 47.474 + 0.093 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.685 \pm 0.155$ \\ $(= 0.491 + 0.285 )$\end{tabular} & \textbf{82}                                                      \\
ratio             & 0.50                                                              & 0.50                                                          & 0.52                                                                                  & 0.66                                                                              & 0.89                                                             \\ \hline
\textbf{60}       & 129.03                                                            & 258.06                                                        & \begin{tabular}[c]{@{}c@{}}$58.151 \pm 0.373$\\  $(= 57.811 + 0.093 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.729 \pm 0.149$ \\ $(= 0.521 + 0.293 )$\end{tabular} & \textbf{78}                                                      \\
ratio             & 0.59                                                              & 0.60                                                          & 0.63                                                                                  & 0.70                                                                              & 0.85                                                             \\ \hline
\textbf{70}       & 150.54                                                            & 301.07                                                        & \begin{tabular}[c]{@{}c@{}}$72.011 \pm 0.450$ \\ $(= 71.641 + 0.092 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.940 \pm 0.186$ \\ $(= 0.674 + 0.340 )$\end{tabular} & \textbf{74}                                                      \\
ratio             & 0.69                                                              & 0.70                                                          & 0.76                                                                                  & 0.90                                                                              & 0.80                                                             \\ \hline
\textbf{80}       & 172.04                                                            & 344.08                                                        & \begin{tabular}[c]{@{}c@{}}$75.648 \pm 0.398$ \\ $(= 75.409 + 0.093 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$0.793 \pm 0.159$ \\ $(= 0.568 + 0.308 )$\end{tabular} & \textbf{76}                                                      \\
ratio             & 0.79                                                              & 0.80                                                          & 0.82                                                                                  & 0.76                                                                              & 0.83                                                             \\ \hline
\textbf{90}       & 193.55                                                            & 387.09                                                        & \begin{tabular}[c]{@{}c@{}}$90.569 \pm 0.476$ \\ $(= 90.355 + 0.093 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$1.194 \pm 0.231$ \\ $(= 0.853 + 0.394 )$\end{tabular} & \textbf{82}                                                      \\
ratio             & 0.89                                                              & 0.90                                                          & 0.98                                                                                  & 1.14                                                                              & 0.89                                                             \\ \hline
\textbf{100}      & 215.05                                                            & 430.10                                                        & \begin{tabular}[c]{@{}c@{}}$99.905 \pm 0.591$ \\ $(= 99.507 + 0.093 )$\end{tabular}   & \begin{tabular}[c]{@{}c@{}}$1.346 \pm 0.257$\\  $(= 0.960 + 0.427 )$\end{tabular} & \textbf{82}                                                      \\
ratio             & 0.99                                                              & 1.00                                                          & 1.08                                                                                  & 1.29                                                                              & 0.89                                                             \\ \hline
\textbf{110}      & 236.56                                                            & 473.11                                                        & \begin{tabular}[c]{@{}c@{}}$106.205 \pm 0.685$ \\ $(= 106.114 + 0.092 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$1.496 \pm 0.284$ \\ $(= 1.067 + 0.460 )$\end{tabular} & \textbf{80}                                                      \\
ratio             & 1.09                                                              & 1.10                                                          & 1.15                                                                                  & 1.43                                                                              & 0.87                                                             \\ \hline
\textbf{120}      & 258.06                                                            & 516.12                                                        & \begin{tabular}[c]{@{}c@{}}$113.461 \pm 0.986$ \\ $(= 113.081 + 0.093 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$1.394 \pm 0.269$ \\ $(= 0.995 + 0.438 )$\end{tabular} & \textbf{88}                                                      \\
ratio             & 1.19                                                              & 1.20                                                          & 1.23                                                                                  & 1.33                                                                              & 0.96                                                             \\ \hline
\textbf{150}      & 322.58                                                            & 645.15                                                        & \begin{tabular}[c]{@{}c@{}}$138.881 \pm 0.910$ \\ $(= 138.528 + 0.094 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$1.809 \pm 0.339$\\  $(= 1.288 + 0.528 )$\end{tabular} & \textbf{94}                                                      \\
ratio             & 1.49                                                              & 1.50                                                          & 1.51                                                                                  & 1.73                                                                              & 1.02                                                             \\ \hline
\textbf{200}      & 430.10                                                            & 860.20                                                        & \begin{tabular}[c]{@{}c@{}}$174.968 \pm 1.870$\\  $(= 174.853 + 0.094 )$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$2.362 \pm 0.429$ \\ $(= 1.682 + 0.648 )$\end{tabular} & \textbf{94}                                                      \\
ratio             & 1.98                                                              & 2.00                                                          & 1.90                                                                                  & 2.26                                                                              & 1.02                                                             \\ \hline
\textbf{Original} & 217.19                                                            & 430.08                                                        & $ 95.243\pm 1.642 $                                                                   & $1.045 \pm 0.255 $                                                                & \textbf{92}                                                     
\end{tabular}
\end{table}